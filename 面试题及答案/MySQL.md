## 1、mysql 索引的数据结构，为什么用 B+ 树而不用 B 树？

首先是查找范围，B+树是在B树的基础上进行变种，非叶子节点用来作索引，而叶子节点有一个指针指向下一个叶子节点，非常便于范围查询；如果是多条的话，B 树需要做局部的中序遍历，可能要跨层访问，而B+ 树由于所有数据在叶子节点，不用跨层，同时由于有链表结构，只需要找到首位，通过链表就能把所有数据取出来了

其次B树不管是叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少。指针数量少的情况下要保存大量数据，只能增加树的高度，导致读IO 操作变多，查询性能变低



## 2、解释 mysql 的聚簇索引和非聚簇索引

聚簇索引是根据主键创建的一棵 B+ 树，聚簇索引的叶子节点存放了表中的所有记录。

非聚簇索引就是根据索引创建的一棵B+ 树，与聚簇索引不同的是，其叶子节点进存放索引键值，以及该索引键值指向的主键。也就是说如果通过非聚簇索引查找数据是是有可能需要进行回表再到聚簇索引中获取数据的



## 3、hash 索引

hash 首先是通过hash 函数进行计算出key的地址，查询时通过独立的地址找到对应的数据，但是 hash 算法可能会出现 **碰撞问题**，也就说不同的 key 通过计算可能得出相同的 地址值。

hash 索引对于单个查询效率是很高的，但是不适合范围查询，范围查询需要把所有数据找出来加载到内存，然后再在内存里筛选目标范围的数据

解决碰撞问题的常见方法是 **链地址法**：碰撞数据使用链表连接，计算 hash 值后，判断该值如果有碰撞，遍历到链表，直到找到真正的 key 所对应的数据为止。



## 4、Mysql 深分页怎么优化，不能分表分区

方案核心思路： 能不能事先知道要从哪个主键ID开始，减少回表的次数

常见解决方案：通过子查询优化

```sql
select * 
from p2p_detail_record ppdr 
where id >= ( select id  from p2p_detail_record ppdr2 where ppdr2 .start_time_stamp >1656666798000 limit 100000,1) 
limit 2000
```



## 5、MySQL 事务并发执行会遇到什么问题

MySQL 事务并发会出现 **脏写，脏读，不可重复读，幻读** 问题

**脏读**：一个事务读到另一个未提交事务修改的数据

**不可重复读**：一个事务修改了另一个未提交事务读取的事务

**幻读**：一个事务根据搜索条件读取了一批数据，该事务未提交，但是另一个事务写入符合该条件的记录，再次读取会发生变更



## 6、mysql 里的事务隔离级别，分别解决了什么问题

MySQL中有4种隔离级别

1. READ UNCOMMITED：未提交读（读未提交）
2. READ COMMITED：已提交读（读已提交）
3. REPEATABLE READ：可重复读
4. SERIALIZABLE：可串行化

| 隔离级别         | 脏读   | 不可重复读 | 幻读   |
| ---------------- | ------ | ---------- | ------ |
| READ UNCOMMITTED | 可能   | 可能       | 可能   |
| READ COMMITTED   | 不可能 | 可能       | 可能   |
| REPEATABLE READ  | 不可能 | 不可能     | 可能   |
| SERIALIZABLE     | 不可能 | 不可能     | 不可能 |

- 在 READ UNCOMMITTTED 隔离级别下，可能发生脏读，不可重复读和幻读现象；
- 在 READ COMMITTED 隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；
- 在 REPEATABLE READ 隔离级别下，可能发生幻读现象，但是不可能发生脏读和不可重复读现象；
- 在 SERIALIZABLE 隔离级别下，上述各种现象都不可能发生。

**脏写：** 脏写这个现象对一致性影响太严重了，无论哪种隔离级别，都不允许出现脏写的情况发生。



## 7、MySQL的存储引擎

MySQL 现在使用的存储引擎是 InnoDB，主要功能有 **插入缓冲**，**二次写**，**自适应hash索引**，**预读** 

**插入缓冲（insert buffer）**：提升插入性能，change buffering 是insert buffer 的加强，insert buffer 只针对 insert 有效，change buffering 对insert，delete，updated（delete + insert），purge 都有效

**二次写（double write）**

1. 当double write 缓存位于系统表空间的存储区域，用来缓存 innodb 的数据页从 innodb buffer poll 中 flush 之后并写入到数据文件之前
2. 当操作系统或数据库进程在数据页写入磁盘的过程中崩溃，可以在 doublewrite 缓存中找到数据页的备份，用来执行 crash 恢复
3. 数据也写入到 doublewrite 缓存的动作所需要的 IO 消耗要小于写入到数据文件的消耗，因此写入操作会以一次大的连续块的方式写入

**自适应 hash 索引（ahi）**：Innodb 存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，此索引成为热数据，建立 hash 索引以提升查询速度，此建立是自动建立哈希索引，故称为自适应哈希索引

- 只适应搜索等值（=）的查询，对于范围，是不使用的

**预读（read ahead）**：InnoDB 使用两种预读算法来提高 I/O 性能，线性预读和随机预读



## 8、innodb 和 myisam 的区别

**InnoDB**

1. 提供了事务，回滚以及系统崩溃修复能力和多版本并发控制的事务安全
2. 支持自增长列
3. 支持外键
4. 支持 MVCC 行级锁
5. 索引使用的是 B+ 树

**优点**：提供良好的事务处理、崩溃修复能力和并发控制

**缺点**：读写效率较差，占用数据空间相对较大

**使用场景**：既有读写也挺频繁是使用 InnoDB。如果不知道如何选择时，也可以用 InnoDB，以应对未来可能存在复杂的业务

**myisam**

不支持事务，不支持行级锁，只支持并发插入的表锁，主要用于高负载的 `select`

**优点**：占用空间小

**缺点**：是不支持事务的完整性和并发性

**使用场景**：表中绝大多数都只是读查询，可以考虑 MyISAM

和InnoDB在**索引存储结构**上最大的区别其实就是聚簇索引和非聚簇索引的区别。myisam 索引文件和数据文件是分离的



## 9、为什么 myisam 不支持事务

MyISAM存储引擎没有redo和undo文件，没法支持事务的ACID特性



## 10、为什么 myisam 不采用和 innodb 相同的方案来解决事务问题？



## 11、为什么数据量大的时候会出现慢 sql

参考文章：**https://blog.csdn.net/xfw17397388089/article/details/125332492**

1. 查询的表，没有加索引
2. 查询的时候，索引无效
3. 查询使用了临时表
4. join或者子查询太多
5. 查询结果数据量太大
6. 锁竞争
7. limit 分页太深



## 12、慢 sql 如何解决 sql 优化

1. 加索引并且保证sql语句确实走了索引，避免全表扫描，首先考虑 `where` 以及 `order by` 涉及列上建立索引
2. 查询出的数据量大（可以采用多次查询降低查询的数据量）
3. 查询时返回了不必要的行和列
4. 减少sql中函数运算与其他计算



## 13、分库分表如何做的

数据库的瓶颈：不管是 IO 瓶颈，还是 CPU 瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务 Service 来看就是，可用数据库连接少甚至无连接可用。

**IO瓶颈**

第一种：磁盘读 IO 瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量 IO，降低查询速度 -> **分库和垂直分表**

第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 -> **分库**

**CPU 瓶颈**

第一种：SQL 问题，如果sql中包含join，group by，order by，非索引字段条件查询，增加 cpu 运算的操作 -> sql 优化，建立合适索引，在业务 Service 层进行业务计算

第二种：单表数据量太大，查询时扫描的行太多，SQL 效率低，CPU 率先出现瓶颈 -> 水平分表

**水平分表原理**

以 **字段** 为依据，按照一定策略，将一个表中的数据拆分到多个 **表** 中

结果：

- 每个 **表** 的 **结构** 都一样
- 每个 **表** 的 **数据** 都不一样，没有交集
- 所有 **表** 的 **并集** 时全量数据

使用场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了 SQL 效率，加重了 CPU 负担，以至于成为瓶颈

**水平分库原理**

以 **字段** 为依据，按照一定策略（hash，range等），将一个 **库** 中的数据拆分到多个**库**中

结果：

- 每个 **库** 的 **结构** 都一样
- 每个 **库** 的 **数据** 都不一样，没有交集
- 所有 **库** 的 **并集** 是全量数据

使用场景：系统绝对并发量上来了，分表难以根本解决问题，并且还没有明显的业务垂直分库

分析：库多了，io 和 cpu 的压力自然可以成倍缓解

**垂直分表原理**

以 **字段** 为依据，按照字段的活跃性，将 **表** 中字段拆到不同的 **表** 中

结果：

- 每个 **表** 的 **结构** 都不一样
- 每个 **表** 的 **数据** 也不一样，一般来说，每个表的 **字段** 至少有一列
- 所有 **表** 的 **并集** 是全量数据

使用场景：系统绝对并发量没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读取磁盘产生大量的随机读 IO，产生 IO 瓶颈

**垂直分库原理**

以 **表** 为依据，按照业务归属不同，将不同的 **表** 拆分到不同的 **库** 中

结果：

- 每个 **库** 的 **结构** 都不一样
- 每个 **库** 的 **数据** 也不一样，没有交集
- 所有 **库** 的 **并集** 是全量数据

使用场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块

**分表分库步骤**

根据容量评估分库或者分表-->选 key（均匀）--> 分表规则（hash或者range）-->执行-->扩容

**水平分库/分表方法**

==按时间分表==：这种方式有一定局限性，当数据有较强的时效性，如微博发送记录，微信消息记录等，很少有用户查询几个月前的数据，就可以按月分表

==RANGE（按区间分表）==

定一个数据范围来进行分表，例如从1~1000000，1000001-2000000，使用一百万一张表的方式

**优点：** 能保证数据较均匀的分散落在不同的库、表中，减轻了数据库压力。

**缺点：** **扩容麻烦、迁移数据时每次都需要重新计算hash值分配到不同的库和表**。



==一致性hash==

优点：通过虚拟节点方式能保证数据较均匀的分散在不同的库，表中，并且新增，删除节点不影响其他节点的数据，高可用，容灾性强



## 14、acid 含义？

事务的四大特性

- 原子性（Atomicity）：数据库把 “要么全做，要么全不做” 这种规则称为原子性
- 隔离性（Isolation）：事务之间相互隔离，不受影响，这与事务的隔离界别密切相关
- 一致性（Consistency）：事务执行前后的状态要一致，可理解为数据一致性
- 持久性（Durable）：事务完成之后，它对数据的修改是永恒的，即使出现故障也能够正常保持



## 15、幻读怎么解决的？

使用间隙锁

**间隙锁和 next-key lock 的引入，帮我们解决了幻读问题，但同时也带来了一些“困扰”**

并发时有可能会出现死锁问题



## 16、用过 mysql 的锁么？有哪些锁？



## 17、mvcc 原理？多版本数据存放在哪？

多版本数据存放在 undo 日志中

**MVCC原理**

第一个概念是**版本链**，就是在每次对数据进行改动时，都会生成一条日志，每个日志中会有一个 roll_pointer 的属性，通过这个属性将这些属性串联成一个链表，这个链被称为版本链

第二个概念是 readView，这个readView主要解决的的问题是，**需要判断版本链中那个版本是当前事务可见的**，这个是通过一个**可见性算法**来进行判断的，readView 中有4个重要的参数，第一个是活跃事务的id集合，第二个是活跃事务中最小事务的id，将要分配给下一个事务的id，生成该readview事务的事务id

不同隔离界别生成 ReadView 的时机不同，**读已提交隔离级别是在每次读取数据前都会生成一个 readview**；**可重复读是在第一次读取时生成一个 readview**



## 18、mysql 脏页？

> 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”

内存里的数据写入磁盘的过程，术语就是 `flush`。

**什么情况会引发数据库的 flush 过程呢？**

1、`InnoDB` 的 `redo log` 写满了。这时候系统会停止所有更新操作，把 `checkpoint` 往前推进，`redo log` 留出空间可以继续写

2、系统内存不足，当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰"脏页"，就要先将脏页写到磁盘

3、MySQL 认为系统 “空闲” 的时候

4、MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘，这样下次 MySQL 启动的时候，就可以直接从磁盘读数据，启动速度会很快。



## 19、redo log，undo log？

redo log，当我们在修改一条记录后为了能让其永久生效，即使后来系统崩溃了，在重启之后也能把这种修改恢复过来，所以我们需要记录修改了什么，比如记录，将第0号表第100号页面偏移量为1000处的值更新为 2，这样在室外提交时，就会把上述内容刷新到磁盘，即使崩溃，重启之后只需要刷新一下数据页即可，这样的记录就可以被称为 redo log，即重做日志。

redo log 占用空间非常小，并且是顺序写入磁盘的



事务需要保证原子性，在事务执行到一半的时候有可能出现系统错误等情况，此时执行过程中可能已经修改了很多东西，为了保证事务的原子性，我们就需要改回原来的样子，这个过程就称为回滚，我们把这些回滚而记录的东西称为撤销日志（undo log）

事务id：如果是我在执行中对某个表执行了增删改操作，那么 InnoDB 存储引擎就会给它分配一个独一无二的事务id，分配方式如下：

- 对于只读事务来说，只有在它第一次对某个用户创建的临时表执行增删改操作时，才会为这个事务分配一个事务id，否则是不分配事务id的
- 对于读写事务来说，只有在它第一次对某个表执行增删改操作时，才会为这个事务分配一个事务id，否则不分配事务id的。



## 20、多列索引的结构

在多个列上创建索引，一个索引可以由15个列组成。

使用准则

- WHERE 只能使用一个索引， MySQL 会寻找它认为最优的那个索引
- 最左原则



## 21、字符串类型和数字类型索引的效率

数字类型索引效率更为高一些



## 22、数据类型隐式转换

程序在编译时会进行一些我们看不到的类型转换，这种转换我们叫隐式类型转换



## 23、join 和 in 怎么选择？有什么区别？

in子查询 和 join 相比
不要轻易使用【in子查询】，由于in子查询总是以外层查询的table作为驱动表，所以如果想用in子查询的话，一定要将外层查询的结果集降下来，降低io次数，降低nested loop循环次数，即：永远用小结果集驱动大的结果集。

> 1.对于mysql，不推荐使用[子查询](https://so.csdn.net/so/search?q=子查询&spm=1001.2101.3001.7020)和join是因为本身join的效率就是硬伤，一旦数据量很大效率就很难保证，强烈推荐分别根据索引单表取数据，然后在程序里面做join，merge数据。
>
> 2.子查询就更别用了，效率太差，执行子查询时，MYSQL需要创建临时表，查询完毕后再删除这些临时表，所以，子查询的速度会受到一定的影响，这里多了一个创建和销毁临时表的过程。
>
> 3.如果是JOIN的话，它是走[嵌套](https://so.csdn.net/so/search?q=嵌套&spm=1001.2101.3001.7020)查询的。小表驱动大表，且通过索引字段进行关联。如果表记录比较少的话，还是OK的。大的话业务逻辑中可以控制处理。
>
> 4.数据库是最底层的，瓶颈往往是数据库。建议数据库只是作为数据store的工具，而不要添加业务上去。





## 24、union 和 union all 有什么区别

1. union去重并排序，union all直接返回合并的结果，不去重也不排序；
2. union all比union性能好；



## 25、跨库分页的实现？

**方法一：全局视野法（例如查询第三页的数据）**

由于分库之后数据在不同的库中，因此到底那些数据才是全局排序的第3页数据呢？分三种情况讨论

| 情况                             | 图示                                                         | 说明                                                         |
| -------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 极端情况，两个库的数据完全一样   | ![在这里插入图片描述](https://img-blog.csdnimg.cn/d0cc40e277d0475182d7f97f6eb648cf.png#pic_center) | 如果两个库的数据完全相同，只需要每个库offset一半，再取半页，就是最终想要的数据（如上图中粉色部分数据） |
| 极端情况，结果数据来自一个库     | ![在这里插入图片描述](https://img-blog.csdnimg.cn/6a4b52cec5e34c0cb7a8b5d48b910a8b.png#pic_center) | 也可能两个库的数据分布及其不均衡，例如db0的所有数据的time都大于db1的所有数据的time，则可能出现：一个库的第3页数据，就是全局排序后的第3页数据（如上图中粉色部分数据） |
| 一般情况，每个库数据各包含一部分 | ![在这里插入图片描述](https://img-blog.csdnimg.cn/ddcd62fd408d44a3922372b9d5eac2ea.png#pic_center) | 正常情况下，全局排序的第3页数据，每个库都会包含一部分（如上图中粉色部分数据） |

由于不清楚到底是那种情况，**所以必须每个库都返回3页数据，所得到的6页数据在服务层进行内存排序**，得到数据全局视野，再取第三页数据，便能够得到想要的全局分页数据

**方案优点**

（1）通过服务层修改SQL语句，扩大数据召回量，能够得到全局视野，业务无损，精准返回所需数据。

方案缺点（显而易见）

（1）每个分库需要返回更多的数据，增大了网络传输量（耗网络）；

（2）除了数据库按照time进行排序，服务层还需要进行二次排序，增大了服务层的计算量（耗CPU）；

（3）最致命的，这个算法随着页码的增大，性能会急剧下降，这是因为SQL改写后每个分库要返回X+Y行数据：返回第3页，offset中的X=200；假如要返回第100页，offset中的X=9900，即每个分库要返回100页数据，数据量和排序量都将大增，性能平方级下降

**方法二：二次查询法**

假设一页只有 5 条数据，查询第 200 页的 SQL 语句为 `select * from T order by time offset 1000 limit5`

**步骤一：查询改写**

1. 将 `select * from T order by time offset 1000 limit 5`，改写为 `select  * from T order by time offset 500 limit 5`，**并投递给所有的分库，注意，这个 offset 的 500 ，来自于全局 offset 的总偏移量1000，除以水平分数据库个数2**
2. 如果是 3 个分库，则可以改写 `select * from T order by time offset 333 limit 5`，假设这三个分库返回的数据 （time，uid）如下

![在这里插入图片描述](https://img-blog.csdnimg.cn/9545e15db6294c95835c1087a4348779.jpeg#pic_center)

3. 可以看到，每个分库都是返回的按照 time 排序的一页数据。

**步骤二：找到所返回 3 页全部数据的最小值**

1. 第一个库，5条数据的time最小值是  1487501123
2. 第二个库，5条数据的time最小值是  1487501133
3. 第三个库，5条数据的time最小值是  1487501143

![在这里插入图片描述](https://img-blog.csdnimg.cn/8d299180dfbd4b678439dd5e49920431.jpeg#pic_center)

4. 故，三页数据中，time 最小值来自第一个库，time_min = 1487501123，这个过程只需要比较各个分库第一条数据，时间复杂度很低

**步骤三：查询二次改写**

1、第一次改写的 SQL 语句是 `select * from T order by time offset 333 limit 5`，第二次要改写成一个 between 语句，between 的起点是 time_min，between的终点是原来每个分库各自返回数据的最大值

2、第一个分库，第一次返回数据的最大值是 1487501523，所以查询改写为 `select * from T order by time where time between time_min and 1487501523 `

3、第二个分库，第一次返回数据的最大值是 1487501323，所以查询改写为 `select * from T order by time where time between time_min and 1487501323 `

4、第二个分库，第一次返回数据的最大值是 1487501553，所以查询改写为 `select * from T order by time where time between time_min and 1487501553 `

5、相对第一次查询，第二次查询条件放款了，故第二次查询会返回比第一次查询结果集更多的数据，假设这三个分库的数据（time,uid）如下

![在这里插入图片描述](https://img-blog.csdnimg.cn/8d9165174d9d4c8388a42ab1c12a80da.jpeg#pic_center)

6、可以看到：

- 由于 time_min 来自原来的分库一，所以分库一的返回结果集和第一次查询相同（所以其实这次访问是可以省略的）
- 分库二的结果集，比第一次多返回了 1 条数据，头部的1条记录（time最小的记录）是新的（上图中粉色记录）
- 分库三的结果集，比第一次多返回了 2 条数据，头部的2条记录（time最小的2条记录）是新的（上图粉色标记）

**步骤四：在每个结果集中虚拟一个 time_min 记录，找到 time_min 在全局的 offset**

![在这里插入图片描述](https://img-blog.csdnimg.cn/7cc84db05702492cbe998a4d54c85430.jpeg#pic_center)

1、在第一个库中，time_min 在第一个库的 offset 是 333

2、在第二个库中，（14888501133，uid_aa）的offset 是 333（根据第一次查询条件得出），故虚拟 time_min 在第二个库的 offset 是 331

3、在第三个库中，（1487501143，uid_aaa）的 offset 是 333（根据第一次查询条件得出），故虚拟 time_min 在第二个库的 offset 是330

4、综上，time_min 在全局的 offset 是 333 + 331 + 330 = 994

**步骤五：既然得到了 time_min 在全局的 offset，就相当于有了全局视野，根据第二次的结果集，就能够得到全局 offset 1000 limit 5 的记录**

![在这里插入图片描述](https://img-blog.csdnimg.cn/6aa1a542a0b04d12ab421fdef81db5c1.jpeg#pic_center)

1、第二次查询在各个分库返回的结果集是有序的，又知道了 time_min 在全局的 offset 是994，一路排下来，容易指导 offset 1000 limit 5 的记录（上图黄色部分）

2、这种方法的优点是：可以精确的返回业务所需数据，每次返回的数据量都非常小，不会随着翻页增加数据的返回量。

3、不足是：需要进行两次数据库查询，**而且 原sql中的limit offset,pagesize 改写成 limit offset/n ,pagesize (注：n为分表个数，如果offset/n除不尽，向下取整，避免最后的结果丢数据）-- 这个的意思，其实就是假设原表这一页的数据，会均分到各个分表(所以，我一再强调，前提是数据是均摊的，如果某个分表的记录很少，极端情况下，甚至是空的，这个就不对了，最终结果会少数据)**



## 26、分库分表后怎么保证全局ID唯一？

**基于雪花（snowFlake）算法生成全局唯一ID**

雪花算法是将 64bit 的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如：时间戳，机器ID，序列号等，最终生成的唯一 ID，有递增性，可以进行排序

不同公司会根据业务不同点，对雪花算法进行一些改造，来支持更庞大的业务。改造后，**一是要让算法中的 ID 生成规则符合业务特点，二是为了解决时间回拨等问题。**



## 27、分库分表后全局ID为什么不使用UUID

- uuid 不具备序列性的特点，因为有时候ID会成为排序字段
- **不具备业务含义**，如果生成的 ID 可以被反解，那么从反解出来的信息中我们可以对 ID来做验证，我们可以从中知道这个 ID 的生成时间，从哪个机房的发号器中生成的
- 不利于提升数据的写入性能
  - 数据进行写入时，都是顺序写入的，ID 递增的时候，只需要追加到后面就好，但如果插入是无序的，就造成数据移动的开销
  - UUID 是由 32 个 16 进制数字组成的字符串，如果作为数据库主键使用比较消耗空间



## 28、主从复制的过程？

主从复制，读写分离一般是一起使用的。目的很简单，就是**为了提高数据库的并发性能**

随着业务量的扩展，如果是单机部署的 MySQL，会导致 I/O 频率过高，**采用主从复制，读写分离可以提高数据的可用性**

**主从复制的原理**

1、当 Master 节点进行 `insert`，`update`，`delete` 操作时，会按顺序写入到 binlog 中

2、salve从库连接 master主库，Master 有多少个 salve 就会创建多少个 binlog dump 线程

3、当 Master 节点的 binlog 发生变化时，binlog dump 线程会通知所有的 salve 节点，并将相应的 binlog 内容推送给 salve 节点

4、I/O 线程接收到 binlog 内容后，将内容写入到本地的 relay-log

5、SQL 线程读取 I/O 线程写入的 rely-log，并且根据 relay-log 的内容对从数据库做相应的操作



## 29、主从复制怎么保证强一致性？

binlog 在记录 event 的时候，多了一条命令：SET TIMESTAMP = 1545313。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回值

因此，不论这个 binlog 是 1 分钟之后被备库执行，还是 3 天后用来恢复这个库的备份，这个 insert 语句插入的行。值都是固定的。也就是说，通过这个条 SET TIMESTAMP 命令，MySQL 就确保了主备数据的一致性



## 30、使用过数据库的 binlog 订阅吗？





































































