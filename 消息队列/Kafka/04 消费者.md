# 一、消费方式

- pull（拉）模式

==consumer 采用 broker 中主动拉取数据。Kafka 采用这种方式。==

- push（推）模式

kafka 没有采用这种方式，因为由 broker 决定消息发送速率，很难适应所有消费者的消费速率。

**pull 模式的不足之处：如果Kafka 没有数据，消费者可能会陷入循环中，一直返回空数据**



# 二、消费者组

Consumer Group（CG）：消费者组，有多个 consumer 组成。形成一个消费者组的条件，是所有消费者的 groupid 相同。

- **消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内**消费者消费
- **消费者组之间互不影响**。所有的消费者都属于某个消费者组，即**消费者组是逻辑上的一个订阅者**

![image-20220615110357811](https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615110357811.png)

![image-20220615110407148](https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615110407148.png)



# 三、消费者组初始化

1、coordinator：辅助实现消费者组的初始化和分区的分配

coordinator 节点选择 = ==groupid的hashcode值 % 50（_consumer_offsets 的分区数量）==



![image-20220615111215551](https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615111215551.png)



# 四、消费者API

## 4.1 独立消费者案例（订阅主题）

1）需求

​	创建一个独立消费者，消费 first 主题中数据

<img src="https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615142108615.png" alt="image-20220615142108615" style="zoom:50%;" />

==注意：在消费者 API 代码中必须配置消费者组 id。命令行启动消费者不填写消费者组 id 会被自动填写随机的消费者组 id==

## 4.2 消费者组案例

1）需求

​	测试同一主题的分区数据，只能由一个消费者组中的一个消费

2）案例实操

​	复制一份基础消费者的代码，在 IDEA 中同时启动，即可启动同一个消费者组中的两个消费者。

代码见 idea 中



## 4.3 Range 分配

1、一个 consumer group  中有多个consumer 组成，一个 topic 有多个 partition 组成，==到底由那个 consumer 来消费那个 partition 的数据。==

2、Kafka 有四种主流的分区分配策略：==Range、RoundRobin、Sticky、CooperativeSticky==

多个通过配置参数 ==partition.assignment.strategy==，修改分区的分配策略。默认策略是 Range + CooperativeSticky。Kafka可以同时使用多个分区策略。

Range 是对每个 topic 而言的

首先对同一个 topic 里面的==分区按照需要进行排序==，并对==消费者按照字母顺序进行排序==

假如现在有 7 个分区，3 个消费者，排序后的分区将会是 0，1，2，3，4，5，6；消费者排序完之后将会是C0，C1，C2。

通过 ==partitions数 / consumer数== 来决定每个消费者应该消费几个分区。==如果除不尽，那么前面几个消费者将多消费 1 个分区==



**2）Range 分区分配策略案例**

（1）修改主题 first 为 7 个分区

```bash
[lixianghong@hadoop102 bin]$ kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic first --partitions 7
```

**==注意：分区数可以增加，但是不能减少==**

（2）创建 3 个消费者

（3）启动 生产者，发送 500 条消息，随机发送到不同的分区



## 4.4 分区分配策略之 RoundRobin

RoundRobin 针对集群中 ==所有Topic 而言==

RoundRobin 轮询分区策略，是把==所有的 partition 和所有的 consumer 都列出来==，然后==按照 hashcode 进行排序==，最后通过==轮询算法==来分配 partition 给到各个消费者

<img src="https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615162640464.png" alt="image-20220615162640464" style="zoom:50%;" />



## 4.5 Sticky 以及再平衡

**粘性分区定义：**可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。

粘性分区==首先会尽量均衡的放置分区到消费者上面==，在出现同一消费者组内消费者出现问题的时候，会==尽量保持原有分配的分区不变化。==



## 4.6 重复消费与漏消费

（1）场景1：**重复消费。**自动提交 offset 引起

![image-20220615202502494](https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615202502494.png)

（2）场景2：**漏消费。**设置offset为手动提交，当 offset 被提交时，数据还在内存中未落盘，此时刚好消费者线程被 kill 掉，那么 offset 已经提交，但是数据未处理，导致这部分内存中的数据丢失。

![image-20220615202652304](https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615202652304.png)

## 4.7 消费者事务

如果想完成 Consumer 端的精准一次性消费，那么需要 ==Kafka 消费端将消费过程和提交 offset 过程做原子绑定==。此时我们需要将 Kafka 的 offset 保存到支持事务的自定义介质（比如 MySQL）

![image-20220615203600773](https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615203600773.png)



## 4.8 生产经验——数据积压（消费者如何提高吞吐量）

1）如果是 Kafka 消费能力不足，可以考虑==增加 Topic 的分区数==，并且同时提升消费组的消费者数量，==消费者数 = 分区数==（两者缺一不可）

<img src="https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615204645528.png" alt="image-20220615204645528" style="zoom:50%;" />

2）如果是下游数据处理不及时：==提高每批次拉取的数量==。批次拉取数据过少（拉取数据 / 处理时间 < 生产速度），使处理的数据小于生产的数据，也会造成数据积压

<img src="https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220615204928590.png" alt="image-20220615204928590" style="zoom:50%;" />









