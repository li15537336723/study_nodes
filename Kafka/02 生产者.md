# kafka 生产者

## 1. 发送流程

在消息发送的过程中，涉及到了==两个线程——main线程和 Sender 线程==。在 main 线程中创建了一个==双端队列 RecordAccumulatoor==。main 线程将消息发送给 RecordAccumulator，Sender线程不断从 RecodAccumulator 中拉取消息发送到 Kafka Broker。

![image-20220303092458348](https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220303092458348.png)

- `batch.size:` 只有数据积累到 batch.size 之后，sender 才会发送数据。默认是 16K

- `linger.ms:` 如果数据迟迟未达到batch.size，sender 等待 linger.ms 设置的时间到了之后就会发送数据。单位 ms，默认是 0 ms，表示没有延迟

应答 acks 的级别

**0：**生产者发送过来的数据，不需要等数据落盘应答

**1：**生产者发送过来的数据，Leader 收到数据后应答

**-1（all）：**生产者发送过来的数据，Leader 和 ISR 队列里面的所有节点收齐数据后应答。-1 和 all 等价



## 2. 异步发送

### 2.1 普通异步发送

1）需求：创建 Kafka 生产者，采用异步的方式发送到 Kafka Broker

**创建 maven 工程**

1. 引入依赖

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>3.0.0</version>
    </dependency>
</dependencies>
```

2. 代码实现

```java
public class CustomProducer {
  public static void main(String[] args) {
    // 0 配置
    Properties properties = new Properties();
    // 连接集群 bootstrap.servers
    properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
    // 指定对应的 key 和 value 的序列化类型 key.serializer
    properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    // 1 创建 Kafka 生产者对象
    KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
    // 2 发送数据
    for (int i = 0; i < 5; i++) {
      kafkaProducer.send(new ProducerRecord<>("first", "atguigu"), new Callback() {
        @Override
        public void onCompletion(RecordMetadata metadata, Exception exception) {
          if (exception == null) {
            System.out.println("主题:" + metadata.topic() + "分区：" + metadata.partition());
          }
        }
      });
    }
    // 3 关闭
    kafkaProducer.close();
  }
}
```



### 2.2 分区策略

<img src="https://lixianghong.oss-cn-beijing.aliyuncs.com/typore/image-20220303110559893.png" alt="image-20220303110559893" style="zoom: 50%;" />

1. ==指明 partition 的情况下，直接将指明的值作为 partition 值==；例如 partition = ==0==，所有数据写入分区 ==0==

2. 没有指明 partition 值但有 key 的情况下，将 **key的hash值** 与 **topic的partition**数进行**取余**得到 partition 值

   例如：key1 的 hash 值 = ==5==，key2 的 hash值 = ==6==，topic 的partition 数 = ==2==，那么 key1 对应的 ==value1 写入 1号分区==，key2 对应的==value2 写入0号分区==

3. 既没有 partition 值有没有 key 值的情况下 Kafka 采用 Sticky Partition（粘性分区器），会随机选择一个分区，并尽可能一直使用该分区，待该分区的 ==batch已满或者已完成，kafka 再随机一个分区进行使用（和上一次的分区不同）==

















































































































































